{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tweepy\n",
    "import datetime\n",
    "import pytz\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "key is secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得したキーを格納\n",
    "# BT = \"himitu\"\n",
    "# CK = \"himitu\"\n",
    "# CS = \"himitu\"\n",
    "# AT = \"himitu\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.Client(bearer_token=BT, consumer_key=CK, consumer_secret=CS, access_token=AT, access_token_secret=AS, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utc2jst(timestamp_utc):\n",
    "    datetime_utc = datetime.datetime.strptime(timestamp_utc + \".000+0000\", \"%Y-%m-%dT%H:%M:%SZ.%f%z\")\n",
    "    datetime_jst = datetime_utc.astimezone(datetime.timezone(datetime.timedelta(hours=+9)))\n",
    "    timestamp_jst = datetime.datetime.strftime(datetime_jst, '%Y-%m-%dT%H:%M:%SZ')\n",
    "    return timestamp_jst\n",
    "\n",
    "def jst2utc(timestamp_jst):\n",
    "    datatime_jst = datetime.datetime.strptime(timestamp_jst + \".000+0000\", \"%Y-%m-%dT%H:%M:%SZ.%f%z\")\n",
    "    datetime_utc = datatime_jst.astimezone(datetime.timezone(datetime.timedelta(hours=-9)))\n",
    "    timestamp_utc = datetime.datetime.strftime(datetime_utc, '%Y-%m-%dT%H:%M:%SZ')\n",
    "    return timestamp_utc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_word = \"place:japan  has:geo lang:ja\"\n",
    "start_time = \"2019-10-05T00:00:00Z\"\n",
    "end_time = \"2019-10-06T23:59:59Z\"\n",
    "item_number = 10\n",
    "#tweets = api.search_all_tweets(query=search_word, end_time=jst2utc(end_time), start_time=jst2utc(start_time), max_results=item_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_timestamp(yyyy,mm,dd):\n",
    "    timestamp =(str(yyyy) + '-' +str(mm)+ '-' +str(dd) +'T00:00:00Z')\n",
    "    return timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_timestamp('2000','02','19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tweepy.Paginator(api.search_all_tweets,\n",
    "                                query = search_word,\n",
    "                                user_fields = ['username', 'public_metrics', 'description', 'location',],\n",
    "                                tweet_fields = ['created_at', 'geo', 'public_metrics', 'text', 'source', 'attachments'],\n",
    "                                media_fields = ['url', 'type', ],\n",
    "                                expansions = ['author_id', 'attachments.media_keys'],\n",
    "                                 end_time=jst2utc(end_time),\n",
    "                                 start_time=jst2utc(start_time),\n",
    "                                 max_results=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tweets = []\n",
    "counter = 0\n",
    "for response in tweepy.Paginator(api.search_all_tweets,\n",
    "                                query = search_word,\n",
    "                                user_fields = ['username', 'public_metrics', 'description', 'location',],\n",
    "                                tweet_fields = ['created_at', 'geo', 'public_metrics', 'text', 'source', 'attachments'],\n",
    "                                media_fields = ['url', 'type', ],\n",
    "                                expansions = ['author_id', 'attachments.media_keys'],\n",
    "                                 end_time=jst2utc(end_time),\n",
    "                                 start_time=jst2utc(start_time),\n",
    "                                 max_results=10):\n",
    "    time.sleep(1)\n",
    "    list_tweets.append(response)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in list_tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username,\n",
    "                              'followers': user.public_metrics['followers_count'],\n",
    "                              'tweets': user.public_metrics['tweet_count'],\n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        if tweet.geo != None:\n",
    "            s = str(tweet['created_at'])\n",
    "            created_at = datetime.datetime.strptime(s, \"%Y-%m-%d %H:%M:%S%z\")\n",
    "            created_at = (str(created_at.year) + '-' + str(created_at.month) + '-' + str(created_at.day) + 'T'+'00:00:00Z')\n",
    "            created_at = utc2jst(created_at)\n",
    "            result.append({'author_id': tweet.author_id,\n",
    "                        'username': author_info['username'],\n",
    "                        'author_followers': author_info['followers'],\n",
    "                        'author_tweets': author_info['tweets'],\n",
    "                        'author_description': author_info['description'],\n",
    "                        'author_location': author_info['location'],\n",
    "                        'text': tweet.text,\n",
    "                        'created_at': created_at,\n",
    "                        'retweets': tweet.public_metrics['retweet_count'],\n",
    "                        'replies': tweet.public_metrics['reply_count'],\n",
    "                        'likes': tweet.public_metrics['like_count'],\n",
    "                        'quote_count': tweet.public_metrics['quote_count'],\n",
    "                        'place_id':tweet.geo['place_id']\n",
    "                        })\n",
    "\n",
    "# Change this list of dictionaries into a dataframe\n",
    "df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
